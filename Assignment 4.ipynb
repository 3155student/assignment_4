{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Jackie Woodlief, Jeff Sharpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Picture\n",
    "Hard Voting: uses predicted class labels for majority rule voting\n",
    "\n",
    "Soft Voting: predicts the class label based on the argmax of the sums of the predicted probabilities\n",
    "\n",
    "For this project we are implementing multiclass classification to determine which of the 10 classes a glacier belongs to (for our dataset, 0-9). We will be doing various data discovery tasks to start with to get a better idea of our data. In particular, we will be plotting the glaciers on a simulated globe based on the given lattitudes and longitudes. We will be using ensemble methods to test their efficiencies, but first we will get a baseline reading with the decision tree classifer and compare with the ensemble methods.\n",
    "\n",
    "We thought about doing multi-class classification according to continent, but thought this would be a bit easier, so we wanted to try something more challenging which is why we choose to use primary classes as our labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data\n",
    "\n",
    "Dataset: https://www.kaggle.com/nsidcorg/glacier-inventory\n",
    "Size: 3.2 MB\n",
    "Entries: 132889\n",
    "Features: 39\n",
    "\n",
    "We looked at, and were seriously considering, several data sets. In the end we choose this one because of it's geographic element and the prospects of implementing multi-class classification. Since we have only worked binary classification for the previous assignments, we thought we would try something more advanced. We are also curious as to how accurate the end results will be.\n",
    "\n",
    "Some of the noticeable stats that you will observe right away is that some of the attributes have a lot of missing values, we'll have to figure out if we should remove those attributes or if it would be better to use an imputer to fill in the missing values. Also, immediately, you can see that some of the attributes are, as they should be, positively correlated, such as longitude and mean elevation accumulation. There are a couple more observations like this that are more-or-less like common sense observations, but it's still good to explore these because it may be unintuitive.\n",
    "\n",
    "Below is our primary class key, we had to find this data from another source since our data set only gave numbers between 0 and 9 (inclusive).\n",
    "\n",
    "Primary Class Key:  \n",
    "0: Uncertain/misc.  \n",
    "1: Continental Ice Sheet  \n",
    "2: Ice-field  \n",
    "3: Ice Cap  \n",
    "4: Outlet Glacier  \n",
    "5: Valley Glacier  \n",
    "6: Mountain Glacier  \n",
    "7: Snowfield/Glacieret  \n",
    "8: Ice Shelf  \n",
    "9: Rock Glacier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These are all the import statements!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_dataset(X, y, axes, col1, col2):\n",
    "    plt.plot(X[:, col1][y==0], X[:, col2][y==0], \"gv\")\n",
    "    plt.plot(X[:, col1][y==1], X[:, col2][y==1], \"c^\")\n",
    "    plt.plot(X[:, col1][y==2], X[:, col2][y==2], \"m<\")\n",
    "    plt.plot(X[:, col1][y==3], X[:, col2][y==3], \"yv\")\n",
    "    plt.plot(X[:, col1][y==4], X[:, col2][y==4], \"k3\")\n",
    "    plt.plot(X[:, col1][y==5], X[:, col2][y==5], \"wo\")\n",
    "    plt.plot(X[:, col1][y==6], X[:, col2][y==6], \"bd\")\n",
    "    plt.plot(X[:, col1][y==7], X[:, col2][y==7], \"ro\")\n",
    "    plt.plot(X[:, col1][y==8], X[:, col2][y==8], \"gd\")\n",
    "    plt.plot(X[:, col1][y==9], X[:, col2][y==9], \"gs\")\n",
    "    plt.axis(axes)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=20)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shelob/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Here we are reading in our dataset\n",
    "\n",
    "glacier_data = pd.read_csv(\"database.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glacier ID</th>\n",
       "      <th>Political Unit</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Basin Code</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Glacier Code</th>\n",
       "      <th>Glacier Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Primary Class</th>\n",
       "      <th>...</th>\n",
       "      <th>Maximum Length</th>\n",
       "      <th>Maximum Length Exposed</th>\n",
       "      <th>Maximum Length Ablation</th>\n",
       "      <th>Mean Depth</th>\n",
       "      <th>Depth Accuracy</th>\n",
       "      <th>Accumulation Orientation</th>\n",
       "      <th>Ablation Orientation</th>\n",
       "      <th>Topographic Map Year</th>\n",
       "      <th>Topographic Map Scale</th>\n",
       "      <th>Photograph Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF5Q112B0001</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>Q112</td>\n",
       "      <td>B0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.672</td>\n",
       "      <td>68.874</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>NE</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF5Q112B0002</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>Q112</td>\n",
       "      <td>B0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.676</td>\n",
       "      <td>68.855</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NW</td>\n",
       "      <td>NW</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF5Q112B0003</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>Q112</td>\n",
       "      <td>B0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.689</td>\n",
       "      <td>68.854</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NW</td>\n",
       "      <td>NW</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF5Q112B0004</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>Q112</td>\n",
       "      <td>B0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.707</td>\n",
       "      <td>68.857</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>NE</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF5Q112B0005</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>ASIA</td>\n",
       "      <td>Q112</td>\n",
       "      <td>B0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.719</td>\n",
       "      <td>68.852</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Glacier ID Political Unit Continent Basin Code Location Code  \\\n",
       "0  AF5Q112B0001    AFGHANISTAN      ASIA       Q112            B0   \n",
       "1  AF5Q112B0002    AFGHANISTAN      ASIA       Q112            B0   \n",
       "2  AF5Q112B0003    AFGHANISTAN      ASIA       Q112            B0   \n",
       "3  AF5Q112B0004    AFGHANISTAN      ASIA       Q112            B0   \n",
       "4  AF5Q112B0005    AFGHANISTAN      ASIA       Q112            B0   \n",
       "\n",
       "  Glacier Code Glacier Name  Latitude  Longitude  Primary Class  \\\n",
       "0            1          NaN    34.672     68.874            9.0   \n",
       "1            2          NaN    34.676     68.855            9.0   \n",
       "2            3          NaN    34.689     68.854            9.0   \n",
       "3            4          NaN    34.707     68.857            9.0   \n",
       "4            5          NaN    34.719     68.852            9.0   \n",
       "\n",
       "        ...         Maximum Length  Maximum Length Exposed  \\\n",
       "0       ...                    1.9                     NaN   \n",
       "1       ...                    0.8                     NaN   \n",
       "2       ...                    1.5                     NaN   \n",
       "3       ...                    1.5                     NaN   \n",
       "4       ...                    2.0                     NaN   \n",
       "\n",
       "   Maximum Length Ablation  Mean Depth  Depth Accuracy  \\\n",
       "0                      NaN         NaN             NaN   \n",
       "1                      NaN         NaN             NaN   \n",
       "2                      NaN         NaN             NaN   \n",
       "3                      NaN         NaN             NaN   \n",
       "4                      NaN         NaN             NaN   \n",
       "\n",
       "   Accumulation Orientation  Ablation Orientation  Topographic Map Year  \\\n",
       "0                        NE                    NE                1959.0   \n",
       "1                        NW                    NW                1959.0   \n",
       "2                        NW                    NW                1959.0   \n",
       "3                        NE                    NE                1959.0   \n",
       "4                       NaN                   NaN                1959.0   \n",
       "\n",
       "   Topographic Map Scale  Photograph Year  \n",
       "0               100000.0              NaN  \n",
       "1               100000.0              NaN  \n",
       "2               100000.0              NaN  \n",
       "3               100000.0              NaN  \n",
       "4               100000.0              NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glacier_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132890 entries, 0 to 132889\n",
      "Data columns (total 39 columns):\n",
      "Glacier ID                     132890 non-null object\n",
      "Political Unit                 132890 non-null object\n",
      "Continent                      132890 non-null object\n",
      "Basin Code                     132890 non-null object\n",
      "Location Code                  132890 non-null object\n",
      "Glacier Code                   132890 non-null object\n",
      "Glacier Name                   46751 non-null object\n",
      "Latitude                       132890 non-null float64\n",
      "Longitude                      132890 non-null float64\n",
      "Primary Class                  131406 non-null float64\n",
      "Glacier Source                 132746 non-null float64\n",
      "Basin Count                    15558 non-null float64\n",
      "Glacier Form                   131813 non-null float64\n",
      "Glacier Activity               132775 non-null float64\n",
      "Activity Start                 4202 non-null float64\n",
      "Activity End                   143 non-null float64\n",
      "Minimum Elevation              117162 non-null float64\n",
      "Minimum Elevation Exposed      89697 non-null float64\n",
      "Mean Elevation                 81599 non-null float64\n",
      "Mean Elevation Accumulation    15473 non-null float64\n",
      "Mean Elevation Ablation        11053 non-null float64\n",
      "Maximum Elevation              115468 non-null float64\n",
      "Snow Line Elevation            28848 non-null float64\n",
      "Snow Line Accuracy             23324 non-null float64\n",
      "Glacier Area                   128374 non-null float64\n",
      "Area Accuracy                  84440 non-null float64\n",
      "Area Exposed                   90737 non-null float64\n",
      "Mean Width                     69966 non-null float64\n",
      "Mean Length                    55258 non-null float64\n",
      "Maximum Length                 102593 non-null float64\n",
      "Maximum Length Exposed         84621 non-null float64\n",
      "Maximum Length Ablation        17051 non-null float64\n",
      "Mean Depth                     70071 non-null float64\n",
      "Depth Accuracy                 78685 non-null float64\n",
      "Accumulation Orientation       114432 non-null object\n",
      "Ablation Orientation           116534 non-null object\n",
      "Topographic Map Year           83697 non-null float64\n",
      "Topographic Map Scale          74586 non-null float64\n",
      "Photograph Year                82464 non-null float64\n",
      "dtypes: float64(30), object(9)\n",
      "memory usage: 39.5+ MB\n"
     ]
    }
   ],
   "source": [
    "glacier_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Primary Class</th>\n",
       "      <th>Glacier Source</th>\n",
       "      <th>Basin Count</th>\n",
       "      <th>Glacier Form</th>\n",
       "      <th>Glacier Activity</th>\n",
       "      <th>Activity Start</th>\n",
       "      <th>Activity End</th>\n",
       "      <th>Minimum Elevation</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean Width</th>\n",
       "      <th>Mean Length</th>\n",
       "      <th>Maximum Length</th>\n",
       "      <th>Maximum Length Exposed</th>\n",
       "      <th>Maximum Length Ablation</th>\n",
       "      <th>Mean Depth</th>\n",
       "      <th>Depth Accuracy</th>\n",
       "      <th>Topographic Map Year</th>\n",
       "      <th>Topographic Map Scale</th>\n",
       "      <th>Photograph Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>132890.000000</td>\n",
       "      <td>132890.000000</td>\n",
       "      <td>131406.000000</td>\n",
       "      <td>132746.000000</td>\n",
       "      <td>15558.000000</td>\n",
       "      <td>131813.000000</td>\n",
       "      <td>132775.000000</td>\n",
       "      <td>4202.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>117162.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>69966.000000</td>\n",
       "      <td>55258.000000</td>\n",
       "      <td>102593.000000</td>\n",
       "      <td>84621.000000</td>\n",
       "      <td>17051.000000</td>\n",
       "      <td>70071.000000</td>\n",
       "      <td>78685.000000</td>\n",
       "      <td>83697.000000</td>\n",
       "      <td>74586.000000</td>\n",
       "      <td>82464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.322101</td>\n",
       "      <td>31.902296</td>\n",
       "      <td>5.716231</td>\n",
       "      <td>0.864712</td>\n",
       "      <td>1.031752</td>\n",
       "      <td>3.738918</td>\n",
       "      <td>0.620448</td>\n",
       "      <td>1967.112327</td>\n",
       "      <td>1986.930070</td>\n",
       "      <td>3502.362063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563436</td>\n",
       "      <td>1.392470</td>\n",
       "      <td>1.417326</td>\n",
       "      <td>1.328634</td>\n",
       "      <td>1.621133</td>\n",
       "      <td>28.415085</td>\n",
       "      <td>2.262960</td>\n",
       "      <td>1970.529565</td>\n",
       "      <td>96838.461508</td>\n",
       "      <td>1974.795899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27.821062</td>\n",
       "      <td>83.860643</td>\n",
       "      <td>1.768668</td>\n",
       "      <td>0.494326</td>\n",
       "      <td>0.327473</td>\n",
       "      <td>2.255064</td>\n",
       "      <td>1.072336</td>\n",
       "      <td>11.348193</td>\n",
       "      <td>6.999648</td>\n",
       "      <td>1735.317842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643816</td>\n",
       "      <td>2.087975</td>\n",
       "      <td>2.560785</td>\n",
       "      <td>1.984061</td>\n",
       "      <td>3.286073</td>\n",
       "      <td>46.480501</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>10.276403</td>\n",
       "      <td>69675.200534</td>\n",
       "      <td>14.107653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-71.657200</td>\n",
       "      <td>-179.918000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1901.000000</td>\n",
       "      <td>1958.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1901.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.616000</td>\n",
       "      <td>-50.375000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1966.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.580000</td>\n",
       "      <td>75.484500</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "      <td>3840.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>90000.000000</td>\n",
       "      <td>1971.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.223000</td>\n",
       "      <td>85.265750</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>5020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.300000</td>\n",
       "      <td>179.680000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>8047.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.800000</td>\n",
       "      <td>76.640000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>7060.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Latitude      Longitude  Primary Class  Glacier Source  \\\n",
       "count  132890.000000  132890.000000  131406.000000   132746.000000   \n",
       "mean       36.322101      31.902296       5.716231        0.864712   \n",
       "std        27.821062      83.860643       1.768668        0.494326   \n",
       "min       -71.657200    -179.918000       0.000000        0.000000   \n",
       "25%        30.616000     -50.375000       6.000000        1.000000   \n",
       "50%        38.580000      75.484500       6.000000        1.000000   \n",
       "75%        49.223000      85.265750       7.000000        1.000000   \n",
       "max        89.300000     179.680000       9.000000        3.000000   \n",
       "\n",
       "        Basin Count   Glacier Form  Glacier Activity  Activity Start  \\\n",
       "count  15558.000000  131813.000000     132775.000000     4202.000000   \n",
       "mean       1.031752       3.738918          0.620448     1967.112327   \n",
       "std        0.327473       2.255064          1.072336       11.348193   \n",
       "min        1.000000       0.000000          0.000000     1901.000000   \n",
       "25%        1.000000       3.000000          0.000000     1963.000000   \n",
       "50%        1.000000       4.000000          0.000000     1967.000000   \n",
       "75%        1.000000       5.000000          1.000000     1975.000000   \n",
       "max        7.000000       9.000000          8.000000     1996.000000   \n",
       "\n",
       "       Activity End  Minimum Elevation       ...           Mean Width  \\\n",
       "count    143.000000      117162.000000       ...         69966.000000   \n",
       "mean    1986.930070        3502.362063       ...             0.563436   \n",
       "std        6.999648        1735.317842       ...             0.643816   \n",
       "min     1958.000000           0.000000       ...             0.000000   \n",
       "25%     1986.000000        1800.000000       ...             0.300000   \n",
       "50%     1986.000000        3840.000000       ...             0.400000   \n",
       "75%     1988.000000        5020.000000       ...             0.700000   \n",
       "max     2002.000000        8047.000000       ...            29.800000   \n",
       "\n",
       "        Mean Length  Maximum Length  Maximum Length Exposed  \\\n",
       "count  55258.000000   102593.000000            84621.000000   \n",
       "mean       1.392470        1.417326                1.328634   \n",
       "std        2.087975        2.560785                1.984061   \n",
       "min        0.020000        0.060000                0.000000   \n",
       "25%        0.500000        0.500000                0.500000   \n",
       "50%        0.800000        0.800000                0.800000   \n",
       "75%        1.510000        1.500000                1.500000   \n",
       "max       76.640000      145.000000              125.000000   \n",
       "\n",
       "       Maximum Length Ablation    Mean Depth  Depth Accuracy  \\\n",
       "count             17051.000000  70071.000000    78685.000000   \n",
       "mean                  1.621133     28.415085        2.262960   \n",
       "std                   3.286073     46.480501        0.999009   \n",
       "min                   0.000000      0.000000        1.000000   \n",
       "25%                   0.200000     12.000000        1.000000   \n",
       "50%                   0.600000     20.000000        2.000000   \n",
       "75%                   2.000000     36.000000        3.000000   \n",
       "max                  64.500000   7060.000000        5.000000   \n",
       "\n",
       "       Topographic Map Year  Topographic Map Scale  Photograph Year  \n",
       "count          83697.000000           74586.000000     82464.000000  \n",
       "mean            1970.529565           96838.461508      1974.795899  \n",
       "std               10.276403           69675.200534        14.107653  \n",
       "min             1901.000000             750.000000      1900.000000  \n",
       "25%             1966.000000           50000.000000      1968.000000  \n",
       "50%             1972.000000           90000.000000      1971.000000  \n",
       "75%             1978.000000          100000.000000      1980.000000  \n",
       "max             1998.000000         1000000.000000      2003.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glacier_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AFRICA                                  59\n",
       "ANTARCTICA                             957\n",
       "ASIA                                 81245\n",
       "EUROPE                               12889\n",
       "NEW ZEALAND AND ANTARCTIC ISLANDS     3704\n",
       "NORTH AMERICA                        24689\n",
       "SOUTH AMERICA                         9347\n",
       "Name: Continent, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at what continents are represented in chronological order\n",
    "\n",
    "glacier_data[\"Continent\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nckdhZmZNuaMwM7Om3FGYmVlT/wfkdKu/rivP0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f1041f9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is essentially a map of the world! The alpha .1 makes it easier to determine concentrations of glaciers\n",
    "\n",
    "glacier_data.plot(kind = \"scatter\", x = \"Longitude\", y = \"Latitude\", alpha = .1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if we can get a better visualization without modifying our data\n",
    "\n",
    "glacier_data.plot(kind = \"scatter\", x = \"Longitude\", y = \"Latitude\", alpha = .3,\n",
    "                 s = glacier_data[\"Glacier Area\"], label = \"Glacier Area\", figsize=(10, 7),\n",
    "                 c = \"Maximum Elevation\", cmap = plt.get_cmap(\"jet\"), colorbar = True,\n",
    "                 )\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's try setting our c value to Primary Class, since that will be our multi-class label, and see what happens\n",
    "# Also, let's try to minimize the size of the circles by dividing glacier area by 1.10\n",
    "\n",
    "glacier_data.plot(kind = \"scatter\", x = \"Longitude\", y = \"Latitude\", alpha = .4,\n",
    "                 s = glacier_data[\"Glacier Area\"] / 1.10, label = \"Glacier Area\", figsize=(10, 7),\n",
    "                 c = \"Primary Class\", cmap = plt.get_cmap(\"jet\"), colorbar = True,\n",
    "                 )\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see if we can zoom in more on the glaciers in Central / South America area, since they are harder to see\n",
    "# because the glaciers there typically have less area than elsewhere\n",
    "\n",
    "glacier_data.plot(kind = \"scatter\", x = \"Longitude\", y = \"Latitude\", alpha = .4,\n",
    "                 s = glacier_data[\"Glacier Area\"], label = \"Glacier Area\", figsize=(10, 7),\n",
    "                 c = \"Primary Class\", cmap = plt.get_cmap(\"jet\"), colorbar = True,\n",
    "                 )\n",
    "\n",
    "plt.axis([-80, -60, -40, 0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info gained from mapping\n",
    "\n",
    "We can clearly see that if you go further north or south, you will typically see higher elevation glaciers, as opposed to the ones found closer to the equator. In addition, if we plot based on primary classes (reference the key above for complete details) we realize that the montain and valley glaciers are usually found within countries (as a decent distance inland), as they should be, like US or Canada or India, etc. and we notice that most of the continental ice sheets and ice fields are found very far north. Also those glaciers are bigger than any others, which makes sense. It's nice to be able to graph this data set like this and realize it on a more global scale!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We should get 30 graphs since 9 of our attributes are objects\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "glacier_data.hist(bins = 50, figsize = (20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation matrix\n",
    "\n",
    "Let's look at the correlation matrix so far to spot any off-the-bat positive / negative correlations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_1 = glacier_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_1[\"Longitude\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_1[\"Maximum Elevation\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_1[\"Minimum Elevation\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are no strong correlations with Primary Class, which is good. It means that our dataset is complex!\n",
    "\n",
    "corr_1[\"Primary Class\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This is the data that will be used as the multiclass labels, let's take a look at the stats of our future labels\n",
    "\n",
    "glacier_data[\"Primary Class\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lastly, to visualize, let's look at some scatter plots\n",
    "\n",
    "The most interesting of these is the relation between latitude and max elevation, the data seems to fit a binomial curve, which is nice because it makes our data a little more exciting. The others I have choosen to plot have little correlations, which could mean that our data set is fairly complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_data.plot(kind = \"scatter\", x = \"Glacier Area\", y = \"Maximum Elevation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_data.plot(kind = \"scatter\", x = \"Glacier Area\", y = \"Minimum Elevation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_data.plot(kind = \"scatter\", x = \"Latitude\", y = \"Maximum Elevation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_data.plot(kind = \"scatter\", x = \"Longitude\", y = \"Glacier Area\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying our dataset\n",
    "\n",
    "Let's copy our data set so that we can refer back to the original at anytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copy = pd.DataFrame.copy(glacier_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "\n",
    "There are some attributes that would likely affect the results, such as the ablation orientation (which is the melting of the glacier in a certain direction) and the accumulation orientation (in what direction has the snow accumlated in). In addition to these, other fields that we will encode are the political unit, continent, location, etc. In short, we are encoding the attributes that could affect the results in our favor. Let's go ahead and do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_cat = copy[\"Ablation Orientation\"]\n",
    "ablation_cat_encoded = encoder.fit_transform(ablation_cat.astype(str))\n",
    "ablation_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_cat = copy[\"Accumulation Orientation\"]\n",
    "accumulation_cat_encoded = encoder.fit_transform(accumulation_cat.astype(str))\n",
    "accumulation_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_cat = copy[\"Political Unit\"]\n",
    "political_cat_encoded = encoder.fit_transform(political_cat)\n",
    "political_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_cat = copy[\"Continent\"]\n",
    "continent_cat_encoded = encoder.fit_transform(continent_cat)\n",
    "continent_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_cat = copy[\"Basin Code\"]\n",
    "basin_cat_encoded = encoder.fit_transform(basin_cat)\n",
    "basin_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_cat = copy[\"Location Code\"]\n",
    "location_cat_encoded = encoder.fit_transform(location_cat)\n",
    "location_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glacier_cat = copy[\"Glacier Code\"]\n",
    "glacier_cat_encoded = encoder.fit_transform(glacier_cat.astype(str))\n",
    "glacier_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we have encoded this data, lets replace the attributes in copy with the encoded versions\n",
    "\n",
    "copy[\"Ablation Orientation\"] = ablation_cat_encoded\n",
    "copy[\"Accumulation Orientation\"] = accumulation_cat_encoded\n",
    "copy[\"Political Unit\"] = political_cat_encoded\n",
    "copy[\"Continent\"] = continent_cat_encoded\n",
    "copy[\"Basin Code\"] = basin_cat_encoded\n",
    "copy[\"Location Code\"] = location_cat_encoded\n",
    "copy[\"Glacier Code\"] = glacier_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets compute the histograms again with the added columns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "copy.hist(bins = 50, figsize = (20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing some of the attributes\n",
    "\n",
    "Now that we have converted some of the attributes to int's to aid in our goal of multi-class classification, we can go ahead and remove some of the attributes that will likely not affect our results, attributes such as a glaciers name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove Glacier Name and Glacier ID\n",
    "\n",
    "copy = copy.drop(\"Glacier Name\", 1)\n",
    "copy = copy.drop(\"Glacier ID\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "copy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We were thinking about removing some of the attributes which see many NaN values, but after doing\n",
    "# a value_counts() on them, we realized that it would make more sense to include them and use the\n",
    "# imputer on the rest\n",
    "\n",
    "copy[\"Maximum Length Exposed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "copy[\"Mean Depth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We experiemnted with removing the attributes that have a lot of missing values, in a couple of cases accuracy\n",
    "# measures increased by a point or two, but overall it worsened the experience, so we decided to just do the \n",
    "# imputer\n",
    "\n",
    "# FOR THIS TRIAL try removing a few more attributes\n",
    "\n",
    "# copy = copy.drop(\"Maximum Length Exposed\", 1)\n",
    "# copy = copy.drop(\"Maximum Length Ablation\", 1)\n",
    "# copy = copy.drop(\"Mean Depth\", 1)\n",
    "# copy = copy.drop(\"Depth Accuracy\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need to focus on cleaning the data we have up\n",
    "\n",
    "We'll start by getting rid of all of the NaN values in our dataset, we will use the imputer to square this away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy = \"median\") # we tried mean here, but the program wouldn't run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = imputer.transform(copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_copy = pd.DataFrame(X, columns = copy.columns)\n",
    "transform_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's re-examine the correlation matrix to see if there are any new points of interest\n",
    "\n",
    "corr_2 = transform_copy.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When looking at the longitude, we notice that Continent, one of the attributes that we encoded, has a very high\n",
    "# negative correlation, so it seems like it was worth while to encode a few of the attributes\n",
    "\n",
    "corr_2[\"Longitude\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_2[\"Maximum Elevation\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_2[\"Ablation Orientation\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_2[\"Accumulation Orientation\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_2[\"Continent\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_2[\"Political Unit\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into test and train sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(transform_copy, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we are further splitting, since the y data will be the classes and the x data will be the rest of the data\n",
    "\n",
    "y_train = train_set[\"Primary Class\"]\n",
    "y_test = test_set[\"Primary Class\"]\n",
    "x_test = test_set.drop(\"Primary Class\", 1)\n",
    "x_train = train_set.drop(\"Primary Class\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head(5) # checking out the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear Separation Visualization\n",
    "\n",
    "As you can see below, our data is not very separable when we compare any two attributes, which means that we have a complex dataset.\n",
    "\n",
    "To minimize the output, we print out the first 51 graphs, if we didn't limit the number of graphs displayed, over 1,000 would be printed to the screen. The first 51 are fairly representative of all of the graphs. You cannot observe separation in any of them, which means that our data set and task is complex; especially since we are doing multiclass classification.\n",
    "\n",
    "Since we are classifying based on 10 classes, it makes it even more non-linearly separable. You'll see that when plotted there is no easy way to separate the data. Maybe you could do some polynomial work on the data, but I would bet that the result would remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are filling an array of the top three important features, as ranked by the random forest (later on in the code)\n",
    "# The next three features are features that are somewhat important!\n",
    "\n",
    "first = x_train.columns.get_loc(\"Glacier Form\")\n",
    "second = x_train.columns.get_loc(\"Glacier Area\")\n",
    "third = x_train.columns.get_loc(\"Mean Depth\")\n",
    "fourth = x_train.columns.get_loc(\"Latitude\")\n",
    "fifth = x_train.columns.get_loc(\"Maximum Length\")\n",
    "sixth = x_train.columns.get_loc(\"Area Exposed\")\n",
    "\n",
    "array_of_indexes = [first, second, third, fourth, fifth, sixth]\n",
    "array_of_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_copy = x_train.values\n",
    "y_train_copy = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for temp1 in range(len(array_of_indexes)):\n",
    "    for temp2 in range(len(array_of_indexes)):\n",
    "        if (temp1 == temp2):\n",
    "            print(\"\")\n",
    "        else:\n",
    "            plot_dataset(x_train_copy, y_train_copy, [x_train_copy[:, array_of_indexes[temp1]].min() - 10, x_train_copy[:, array_of_indexes[temp1]].max() + 10, x_train_copy[:, array_of_indexes[temp2]].min() - 10, x_train_copy[:, array_of_indexes[temp2]].max() + 10], array_of_indexes[temp1], array_of_indexes[temp2]) #Departure time and distance plotted\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier (1-split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf.fit(x_train, y_train)\n",
    "dt_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf.classes_ # verifying that we are using multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt_clf, x_train, y_train, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_dt = cross_val_predict(dt_clf, x_train, y_train, cv = 3)\n",
    "y_train_predict_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix is a bit different for multi-class problems\n",
    "\n",
    "# errors per class?\n",
    "confusion_dt = confusion_matrix(y_train, y_train_predict_dt)\n",
    "confusion_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(confusion_dt, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Error\n",
    "\n",
    "Since we are doing a multi-class classification problem, we cannot compute the ROC curve in the same manner as binary classification, so instead we are plotting error by class to show performance in this regard. In the below plot, rows represent the actual class and the columns represent predicted ones. In other words, the brighter a column is, the more times a class was misclassified as that columns class. The below plot is very nice for the decision tree classifier, as there are virtually no super bright columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_of_row = confusion_dt.sum(axis = 1, keepdims = True)\n",
    "norm_conf_dt = confusion_dt / sum_of_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(norm_conf_dt, 0)\n",
    "plt.matshow(norm_conf_dt, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train, y_train_predict_dt, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train, y_train_predict_dt, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train, y_train_predict_dt, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions = dt_clf.predict(x_test) #predict how the classes from our test set\n",
    "dt_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, dt_predictions)) #88.5% accurate on our test set!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base performance\n",
    "\n",
    "Our base performance when using the decision tree classifier is the 87.90% f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier\n",
    "\n",
    "Now lets take a look at our bagging classifer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bagg_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators = 500,\n",
    "    max_samples = 100, bootstrap = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagg_clf.fit(x_train, y_train)\n",
    "bagg_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagg_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(bagg_clf, x_train, y_train, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_bagg = cross_val_predict(bagg_clf, x_train, y_train, cv = 3)\n",
    "y_train_predict_bagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_bagg = confusion_matrix(y_train, y_train_predict_bagg)\n",
    "confusion_bagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(confusion_bagg, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_of_row_bagg = confusion_bagg.sum(axis = 1, keepdims = True)\n",
    "norm_conf_bagg = confusion_bagg / sum_of_row_bagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(norm_conf_bagg, 0)\n",
    "plt.matshow(norm_conf_bagg, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick evaluation\n",
    "\n",
    "As you can see from the above plot, many classes were misclassified as class 6, especially when the class was actually a class 2 glacier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train, y_train_predict_bagg, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train, y_train_predict_bagg, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train, y_train_predict_bagg, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagg_predictions = bagg_clf.predict(x_test) #predict how the classes from our test set\n",
    "bagg_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, bagg_predictions)) #88.5% accurate on our test set!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 16, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf.fit(x_train, y_train)\n",
    "random_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(random_clf, x_train, y_train, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_random = cross_val_predict(random_clf, x_train, y_train, cv = 3)\n",
    "y_train_predict_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_random = confusion_matrix(y_train, y_train_predict_random)\n",
    "confusion_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(confusion_random, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_of_row_rf = confusion_random.sum(axis = 1, keepdims = True)\n",
    "norm_conf_rf = confusion_random / sum_of_row_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.fill_diagonal(norm_conf_rf, 0)\n",
    "plt.matshow(norm_conf_rf, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Error Evaluation\n",
    "\n",
    "We have the same problem with the random forest ensemble that we do with the bagg, many actual classes get misclassified as class 6. That seems to be where most of the error lies. Let's see if adaboost ensemble suffers from the same issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train, y_train_predict_random, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train, y_train_predict_random, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train, y_train_predict_random, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_predictions = random_clf.predict(x_test) #predict how the classes from our test set\n",
    "random_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, random_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth = 1), n_estimators = 200,\n",
    "    algorithm = \"SAMME.R\", learning_rate = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf.fit(x_train, y_train)\n",
    "ada_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(ada_clf, x_train, y_train, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_ada = cross_val_predict(ada_clf, x_train, y_train, cv = 3)\n",
    "y_train_predict_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_ada = confusion_matrix(y_train, y_train_predict_ada)\n",
    "confusion_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(confusion_ada, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_of_row_ada = confusion_ada.sum(axis = 1, keepdims = True)\n",
    "norm_conf_ada = confusion_ada / sum_of_row_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(norm_conf_ada, 0)\n",
    "plt.matshow(norm_conf_ada, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Error Evaluation\n",
    "\n",
    "As you can see from the above plot of class error, many of the columns are bright, which means that many classes got misclassified. This lines up with the other performance measures that we test. The adaboost ensemble is not performing well for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train, y_train_predict_ada, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train, y_train_predict_ada, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train, y_train_predict_ada, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_predictions = ada_clf.predict(x_test) #predict how the classes from our test set\n",
    "ada_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, ada_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Ensemble method\n",
    "\n",
    "For our purposes and data set the best ensemble method to use is the bagging classifier. It outperformed the random forest and the adaboost ensemble methods, especially the adaboost. Adaboost saw the worst results of the three ensemble classifiers we tested. While bagging classifier was the best, a kind of close second was the random forest, which saw similar results that were only slightly worse than bagging. With this being said though, it's worth pointing out that the best classifier we tested was actually the base decision tree classifier that we implemented, it saw much better results than any of the ensemble classifiers we tested and compared it with. This was surprising, initially we thought that we would see the best performance from random forest ensemble, since in the past random forest always seemed to yield the best results. We do have a different data set though, so the effectiveness of each classifier probably varies by data sets and other variables such as whether or not its a binary or multi-class classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Feature Importance\n",
    "\n",
    "Next, we'll see how the Random Forest Classifier ranked each feature in terms of relative importance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the raw feature importance's\n",
    "\n",
    "random_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now let's make it easier for the user to view\n",
    "\n",
    "for name, score in zip(list(x_train), random_clf.feature_importances_):\n",
    "    print(name, score) # remember these are percents, so multiple by 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "When we look at the above results of the feature importances we can see that the most important feature in determinations is glacier form, which is at 17%. Other than this attribute, there are two more whose percents are above 10%, glacier area (10.5 %) and mean depth (10.38%). It's odd that mean depth has such a high weight on the results of random forest, mostly because the majority of its values were NaN, so we used the imputer to find the median. We experimented with dropping this column completely, but we saw worse results in most of our classifiers, so we decided to keep this field. It's just odd because the majority of the values for any given glacier is the median of mean depth before the NaN values were ruled out. There were a few attributes that saw a 0% importance, activity end, basin count, mean elevation accumulation and snow line accuracy. In the future we could probably just go ahead and drop these columns from the calculations completely, but we kept them in our data set so that we could show and realize some 0% feature importances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Present Solution\n",
    "\n",
    "If we were pitching this to a client, we would present the solution that saw the best performance / accuracy measures. If the client requested ensemble methods to be used then we would inform them that in their context the bagging classifier would be the best ensemble method to use. We would tell them that random forest would be a very close alternative and to stay away from ada boost (at least with the parameters that we used). For the clients data, and although we say good results when classifying glacier classes, we may suggest that the user use different labels to see if they could realize better results; different labels such as maybe continent or political unit. The user would have to change up their goal slightly, but it may be worth it if they could get better results. In addition, by first classifying according to the continent or political unit, it may segway into finding out more info about the data. So the client could revisit the primary class labels and implement different attributes (in that they could create their own based on their findings classifying the continent or political unit).\n",
    "\n",
    "So far we learned that it is possible to realize good results when doing multi-class classification, even with 10 classes. We were surprised that the best classifier that we used was the base decision tree classifier, we thought for sure each and every ensemble classifier would out-perform it. In the future maybe we could do grid search and find the optimal hyper parameters for the ensemble methods. If we did this, I am sure we could get better results. Also, something else that may be affecting this is the data, if we used an entirely different data set, then we may realize completely different results. We may see that the ensemble methods performed way better than the base classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan for the Future\n",
    "\n",
    "In the end, each ensemble method (and the base decision tree classifier) except for adaboost performed well. The best was the decision tree classifier, which is ironic because it's not an ensemble implementation. One reason that this could be the case is because we need more data. Our data set wasn't small but it also wasn't large. In the future, we can get more data, which will probably improve the performance of the various ensemble methods. Other than the need for more data, our system works well and should work just as well in the future (actually, it may get better). As of now, we are satisfied with the system and saw great multi-class classification accuracy. Also, as we mentioned previously, if we performed grid search to find the optimal parameters to use for the ensemble methods, we could likely get way better performance from them. This would be something to implement in the future as well!\n",
    "\n",
    "Additionally, a theme with class errors that presented itself in all of the ensembles was the fact that various class glaciers kept getting misclassified as class 6. In the future we could explore this issue and maybe combine classes, or some other alternative, and see if we can get the performance up. Maybe we could do something in regards to dimensionality reduction, especially since some of the features are 0% important to the random forest ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
